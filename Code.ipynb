{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,RepeatedStratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df      = pd.read_csv('archive/train.csv')\n",
    "test_df       = pd.read_csv('archive/test.csv')\n",
    "submission_df = pd.read_csv('archive/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Addition Features\n",
    "combine_set=pd.concat([train_df,test_df],axis=0)\n",
    "combine_set['City_Code_Patient'].fillna(-99,inplace=True)\n",
    "combine_set['Bed Grade'].fillna(5,inplace=True)\n",
    "combine_set['Unique_Hospital_per_patient']=combine_set.groupby(['patientid'])['Hospital_code'].transform('nunique')\n",
    "combine_set['Unique_patient_per_hospital']=combine_set.groupby(['Hospital_code'])['patientid'].transform('nunique')\n",
    "combine_set['Unique_patient_per_Department']=combine_set.groupby(['Department'])['patientid'].transform('nunique')\n",
    "combine_set['Total_deposit_paid_by_patient_in_each_hospital']=combine_set.groupby(['Hospital_code','patientid'])['Admission_Deposit'].transform('sum')\n",
    "combine_set['Min_Severity_of_Illness'] = combine_set.groupby('patientid')['Severity of Illness'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "#Encoding categorical variables by frequency encoding and label encoding\n",
    "for col in combine_set.select_dtypes(include='object').columns:\n",
    "    if col not in ['Age','Stay']:\n",
    "        fe=combine_set.groupby([col]).size()/len(combine_set)\n",
    "        combine_set[col]=combine_set[col].apply(lambda x: fe[x])   \n",
    "        # combine_set[col]  = pd.get_dummies(combine_set[col].astype(str))         \n",
    "    elif col!='Stay':\n",
    "        combine_set[col]=le.fit_transform(combine_set[col].astype(str))\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train and test\n",
    "\n",
    "X=combine_set[combine_set['Stay'].isnull()==False].drop(['case_id','Stay'],axis=1)\n",
    "y=le.fit_transform(combine_set[combine_set['Stay'].isnull()==False]['Stay'])\n",
    "y=pd.DataFrame(y,columns=['Stay'])\n",
    "X_main_test=combine_set[combine_set['Stay'].isnull()==True].drop(['case_id','Stay'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kf=KFold(n_splits=10,shuffle=True,random_state=294)\n",
    "kf=KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "preds_1   = {}\n",
    "y_pred_1  = []\n",
    "acc_score = []\n",
    "\n",
    "for i,(train_idx,val_idx) in enumerate(kf.split(X)):    \n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx,:], y.iloc[train_idx]\n",
    "    \n",
    "    X_val, y_val = X.iloc[val_idx, :], y.iloc[val_idx]\n",
    "\n",
    "    print('\\nFold: {}\\n'.format(i+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classes réelles : 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Nombre de classes réelles :\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de y_train : <class 'pandas.core.frame.DataFrame'>\n",
      "Classes réelles : [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Nombre de classes réelles : 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Vérifier le type de y_train\n",
    "print(\"Type de y_train :\", type(y_train))\n",
    "\n",
    "# Vérifier les valeurs uniques dans y_train\n",
    "unique_classes = np.unique(y_train)\n",
    "print(\"Classes réelles :\", unique_classes)\n",
    "print(\"Nombre de classes réelles :\", len(unique_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg=LGBMClassifier(device=\"gpu\", \n",
    "                      gpu_platform_id= 0,\n",
    "                      max_bin=63,#Theoretically best speeds using LGBM\n",
    "                      gpu_device_id= 0,\n",
    "                      boosting_type='gbdt',\n",
    "                      learning_rate=0.04,\n",
    "                      # max_depth=15,\n",
    "                      # num_leaves = 150,\n",
    "                      objective='multi_class',\n",
    "                      num_class=11,                      \n",
    "                      n_estimators=50000,\n",
    "                      metric='multi_error',\n",
    "                      colsample_bytree=0.8,\n",
    "                      min_child_samples=228,\n",
    "                      reg_alpha=1,\n",
    "                      reg_lambda=1,\n",
    "                      # random_state=294,\n",
    "                      n_jobs=-1,\n",
    "\n",
    "                       ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# cette entrainement ne marche pas  ma il me faut update mon Classifier\n",
    "\n",
    "lg.fit(X_train, y_train\n",
    "    #,categorical_feature = categorical_features\n",
    "    ,eval_metric='multi_error'\n",
    "    ,eval_set=[(X_train, y_train),(X_val, y_val)]\n",
    "    ,early_stopping_rounds=100\n",
    "    ,verbose=50\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 431\n",
      "[LightGBM] [Info] Number of data points in the train set: 254751, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -2.600490\n",
      "[LightGBM] [Info] Start training from score -1.404432\n",
      "[LightGBM] [Info] Start training from score -1.291491\n",
      "[LightGBM] [Info] Start training from score -1.753011\n",
      "[LightGBM] [Info] Start training from score -3.297876\n",
      "[LightGBM] [Info] Start training from score -2.209512\n",
      "[LightGBM] [Info] Start training from score -4.760503\n",
      "[LightGBM] [Info] Start training from score -3.443865\n",
      "[LightGBM] [Info] Start training from score -4.186257\n",
      "[LightGBM] [Info] Start training from score -4.742779\n",
      "[LightGBM] [Info] Start training from score -3.862816\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Marche\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Préparation des données d'entraînement X_train et y_train\n",
    "\n",
    "#  les paramètres du modèle\n",
    "#diminuer le nombre de parametre n_estimators sa peut cracher ma machine\n",
    "params = {\n",
    "    'max_bin':63,\n",
    "    'boosting_type':'gbdt',\n",
    "    'learning_rate':0.04,\n",
    "    'objective': 'multiclass',\n",
    "    'metric': ['multi_logloss'],\n",
    "    'num_class': 11,\n",
    "    'n_estimators':5000,\n",
    "    'metric':'multi_error',\n",
    "    'colsample_bytree':0.8,\n",
    "    'min_child_samples':228,\n",
    "    'reg_alpha':1,\n",
    "    'reg_lambda':1,\n",
    "    'n_jobs':-1,\n",
    "      \n",
    "    # Autres paramètres du modèle\n",
    "}\n",
    "\n",
    "# Création d'un dataset LightGBM à partir des données d'entraînement\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model = lgb.train(params, train_data)\n",
    "\n",
    "# Utilisation le modèle pour faire des prédictions donnee de test\n",
    "\n",
    "predictions = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.57825128e-02 2.25571592e-01 4.29950352e-01 ... 2.97488538e-04\n",
      "  7.75231014e-04 1.21426089e-04]\n",
      " [2.93246145e-02 2.72643411e-01 3.91421628e-01 ... 9.77374230e-05\n",
      "  3.29480386e-05 9.66433672e-05]\n",
      " [3.50256365e-02 1.06568212e-01 2.42831215e-01 ... 1.39432647e-02\n",
      "  3.80074392e-04 7.12770460e-04]\n",
      " ...\n",
      " [8.08279297e-05 1.04924945e-01 4.73300094e-03 ... 5.82868862e-04\n",
      "  3.39215726e-03 8.80690326e-03]\n",
      " [1.29867679e-03 3.41108657e-02 2.93826342e-02 ... 1.82648142e-03\n",
      "  1.27520189e-02 2.63779959e-03]\n",
      " [1.67089500e-03 8.50772279e-02 5.72075848e-02 ... 4.75330715e-03\n",
      "  2.12118003e-02 2.04017092e-03]]\n"
     ]
    }
   ],
   "source": [
    "#affichage des predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.22      0.28      4692\n",
      "           1       0.43      0.48      0.46     15596\n",
      "           2       0.43      0.64      0.52     17470\n",
      "           3       0.39      0.25      0.31     11023\n",
      "           4       0.16      0.01      0.03      2327\n",
      "           5       0.42      0.48      0.45      7058\n",
      "           6       0.31      0.02      0.03       563\n",
      "           7       0.36      0.12      0.17      2117\n",
      "           8       0.40      0.24      0.30       965\n",
      "           9       0.44      0.10      0.16       545\n",
      "          10       0.60      0.50      0.55      1331\n",
      "\n",
      "    accuracy                           0.43     63687\n",
      "   macro avg       0.39      0.28      0.30     63687\n",
      "weighted avg       0.41      0.43      0.40     63687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convertir les prédictions en classes\n",
    "y_pred_class = [np.argmax(pred) for pred in predictions]\n",
    "\n",
    "# Calculer le rapport de classification\n",
    "report = classification_report(y_val, y_pred_class)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "# Calculer les courbes ROC ne se trace pas pour les probleme de classification multiclasse uniquement binaire mais on peut faire plusieurs courbe\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(X_val, y_val)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label='Courbe ROC (AUC = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('Taux de faux positifs')\n",
    "# plt.ylabel('Taux de vrais positifs')\n",
    "# plt.title('Courbe ROC')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "# Calculer les courbes de précision-rappel\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(X_val, y_val)\n",
    "\n",
    "# Tracer la courbe de précision-rappel\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=11, label='Courbe de précision-rappel')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Rappel')\n",
    "plt.ylabel('Précision')\n",
    "plt.title('Courbe de précision-rappel')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "print(accuracy_score(y_val,model.predict(X_val))*100)\n",
    "    \n",
    "acc = accuracy_score(y_val,model.predict(X_val))*100\n",
    "acc_score.append(acc)\n",
    "print(\"Score : \",acc)    \n",
    "y_pred_1.append(model.predict_proba(X_main_test))\n",
    "    \n",
    "\n",
    "\n",
    "# preds_1[i+1]=lg.predict_proba(X_main_test)\n",
    "# y_pred_1.append(lg.predict_proba(X_main_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final_1 = np.mean(np.array(y_pred_1),axis=0)\n",
    "    \n",
    "print('mean accuracy score: {}'.format((sum(acc_score)/10)))\n",
    "\n",
    "preds_1=np.argmax(y_pred_final_1,axis=1)\n",
    "\n",
    "print(preds_1.shape)\n",
    "submission_df['Stay']=le.inverse_transform(preds_1.astype(int))\n",
    "# submission_df[0] = y_pred_final_1[:,0]\n",
    "# submission_df[1] =y_pred_final_1[:,1]\n",
    "\n",
    "# Download Submission File :\n",
    "display(\"submission_df\",submission_df)\n",
    "sub_file_name_1 = \"BEST_11_CV=42.96_LB=WAIT_LGBM-1.csv\"\n",
    "\n",
    "\n",
    "submission_df.to_csv(sub_file_name_1,index=False)\n",
    "submission_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
