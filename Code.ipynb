{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,RepeatedStratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df      = pd.read_csv('archive/train.csv')\n",
    "test_df       = pd.read_csv('archive/test.csv')\n",
    "submission_df = pd.read_csv('archive/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Addition Features\n",
    "combine_set=pd.concat([train_df,test_df],axis=0)\n",
    "combine_set['City_Code_Patient'].fillna(-99,inplace=True)\n",
    "combine_set['Bed Grade'].fillna(5,inplace=True)\n",
    "combine_set['Unique_Hospital_per_patient']=combine_set.groupby(['patientid'])['Hospital_code'].transform('nunique')\n",
    "combine_set['Unique_patient_per_hospital']=combine_set.groupby(['Hospital_code'])['patientid'].transform('nunique')\n",
    "combine_set['Unique_patient_per_Department']=combine_set.groupby(['Department'])['patientid'].transform('nunique')\n",
    "combine_set['Total_deposit_paid_by_patient_in_each_hospital']=combine_set.groupby(['Hospital_code','patientid'])['Admission_Deposit'].transform('sum')\n",
    "combine_set['Min_Severity_of_Illness'] = combine_set.groupby('patientid')['Severity of Illness'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "#Encoding categorical variables by frequency encoding and label encoding\n",
    "for col in combine_set.select_dtypes(include='object').columns:\n",
    "    if col not in ['Age','Stay']:\n",
    "        fe=combine_set.groupby([col]).size()/len(combine_set)\n",
    "        combine_set[col]=combine_set[col].apply(lambda x: fe[x])   \n",
    "        # combine_set[col]  = pd.get_dummies(combine_set[col].astype(str))         \n",
    "    elif col!='Stay':\n",
    "        combine_set[col]=le.fit_transform(combine_set[col].astype(str))\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train and test\n",
    "\n",
    "X=combine_set[combine_set['Stay'].isnull()==False].drop(['case_id','Stay'],axis=1)\n",
    "y=le.fit_transform(combine_set[combine_set['Stay'].isnull()==False]['Stay'])\n",
    "y=pd.DataFrame(y,columns=['Stay'])\n",
    "X_main_test=combine_set[combine_set['Stay'].isnull()==True].drop(['case_id','Stay'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kf=KFold(n_splits=10,shuffle=True,random_state=294)\n",
    "kf=KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "preds_1   = {}\n",
    "y_pred_1  = []\n",
    "acc_score = []\n",
    "\n",
    "for i,(train_idx,val_idx) in enumerate(kf.split(X)):    \n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx,:], y.iloc[train_idx]\n",
    "    \n",
    "    X_val, y_val = X.iloc[val_idx, :], y.iloc[val_idx]\n",
    "\n",
    "    print('\\nFold: {}\\n'.format(i+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classes réelles : 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Nombre de classes réelles :\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de y_train : <class 'pandas.core.frame.DataFrame'>\n",
      "Classes réelles : [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Nombre de classes réelles : 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Vérifier le type de y_train\n",
    "print(\"Type de y_train :\", type(y_train))\n",
    "\n",
    "# Vérifier les valeurs uniques dans y_train\n",
    "unique_classes = np.unique(y_train)\n",
    "print(\"Classes réelles :\", unique_classes)\n",
    "print(\"Nombre de classes réelles :\", len(unique_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg=LGBMClassifier(device=\"gpu\", \n",
    "                      gpu_platform_id= 0,\n",
    "                      max_bin=63,#Theoretically best speeds using LGBM\n",
    "                      gpu_device_id= 0,\n",
    "                      boosting_type='gbdt',\n",
    "                      learning_rate=0.04,\n",
    "                      # max_depth=15,\n",
    "                      # num_leaves = 150,\n",
    "                      objective='multi_class',\n",
    "                      num_class=11,                      \n",
    "                      n_estimators=50000,\n",
    "                      metric='multi_error',\n",
    "                      colsample_bytree=0.8,\n",
    "                      min_child_samples=228,\n",
    "                      reg_alpha=1,\n",
    "                      reg_lambda=1,\n",
    "                      # random_state=294,\n",
    "                      n_jobs=-1,\n",
    "\n",
    "                       ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# cette entrainement ne marche pas  ma il me faut update mon Classifier\n",
    "\n",
    "lg.fit(X_train, y_train\n",
    "    #,categorical_feature = categorical_features\n",
    "    ,eval_metric='multi_error'\n",
    "    ,eval_set=[(X_train, y_train),(X_val, y_val)]\n",
    "    ,early_stopping_rounds=100\n",
    "    ,verbose=50\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 430\n",
      "[LightGBM] [Info] Number of data points in the train set: 254751, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -2.602660\n",
      "[LightGBM] [Info] Start training from score -1.405504\n",
      "[LightGBM] [Info] Start training from score -1.291934\n",
      "[LightGBM] [Info] Start training from score -1.753033\n",
      "[LightGBM] [Info] Start training from score -3.304269\n",
      "[LightGBM] [Info] Start training from score -2.207904\n",
      "[LightGBM] [Info] Start training from score -4.747294\n",
      "[LightGBM] [Info] Start training from score -3.432622\n",
      "[LightGBM] [Info] Start training from score -4.177517\n",
      "[LightGBM] [Info] Start training from score -4.736493\n",
      "[LightGBM] [Info] Start training from score -3.865436\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train, label\u001b[38;5;241m=\u001b[39my_train)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Utilisation le modèle pour faire des prédictions donnee de test\u001b[39;00m\n\u001b[0;32m     33\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[1;32mc:\\python install\\lib\\site-packages\\lightgbm\\engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python install\\lib\\site-packages\\lightgbm\\basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Marche\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Préparation des données d'entraînement X_train et y_train\n",
    "\n",
    "#  les paramètres du modèle\n",
    "#diminuer le nombre de parametre n_estimators sa peut cracher ma machine\n",
    "params = {\n",
    "    'max_bin':63,\n",
    "    'boosting_type':'gbdt',\n",
    "    'learning_rate':0.04,\n",
    "    'objective': 'multiclass',\n",
    "    'metric': ['multi_logloss'],\n",
    "    'num_class': 11,\n",
    "    'n_estimators':5000,\n",
    "    'metric':'multi_error',\n",
    "    'colsample_bytree':0.8,\n",
    "    'min_child_samples':228,\n",
    "    'reg_alpha':1,\n",
    "    'reg_lambda':1,\n",
    "    'n_jobs':-1,\n",
    "      \n",
    "    # Autres paramètres du modèle\n",
    "}\n",
    "\n",
    "# Création d'un dataset LightGBM à partir des données d'entraînement\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model = lgb.train(params, train_data)\n",
    "\n",
    "# Utilisation le modèle pour faire des prédictions donnee de test\n",
    "\n",
    "predictions = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04423404 0.14202437 0.46353668 ... 0.00295867 0.0018761  0.03028334]\n",
      " [0.05435923 0.17139041 0.42558638 ... 0.00465259 0.00416769 0.03070038]\n",
      " [0.05511342 0.38970614 0.33962049 ... 0.00454809 0.0030121  0.00792457]\n",
      " ...\n",
      " [0.0083145  0.08465096 0.01702956 ... 0.00352462 0.01987457 0.01629955]\n",
      " [0.12011986 0.32937458 0.34355589 ... 0.00130039 0.00197271 0.00142066]\n",
      " [0.12672843 0.40300733 0.28907694 ... 0.00212159 0.00151663 0.00264064]]\n"
     ]
    }
   ],
   "source": [
    "#affichage des predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.16      0.23      4745\n",
      "           1       0.43      0.50      0.46     15598\n",
      "           2       0.42      0.67      0.52     17401\n",
      "           3       0.44      0.23      0.30     11074\n",
      "           4       0.00      0.00      0.00      2324\n",
      "           5       0.39      0.51      0.45      7025\n",
      "           6       0.20      0.00      0.00       581\n",
      "           7       0.31      0.01      0.02      2111\n",
      "           8       0.36      0.15      0.21       947\n",
      "           9       0.49      0.03      0.06       542\n",
      "          10       0.55      0.43      0.48      1339\n",
      "\n",
      "    accuracy                           0.43     63687\n",
      "   macro avg       0.37      0.24      0.25     63687\n",
      "weighted avg       0.41      0.43      0.39     63687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convertir les prédictions en classes\n",
    "y_pred_class = [np.argmax(pred) for pred in predictions]\n",
    "\n",
    "# Calculer le rapport de classification\n",
    "report = classification_report(y_val, y_pred_class)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "# Calculer les courbes ROC ne se trace pas pour les probleme de classification multiclasse uniquement binaire mais on peut faire plusieurs courbe\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(X_val, y_val)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label='Courbe ROC (AUC = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('Taux de faux positifs')\n",
    "# plt.ylabel('Taux de vrais positifs')\n",
    "# plt.title('Courbe ROC')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "# Calculer les courbes de précision-rappel\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(X_val, y_val)\n",
    "\n",
    "# Tracer la courbe de précision-rappel\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=11, label='Courbe de précision-rappel')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Rappel')\n",
    "plt.ylabel('Précision')\n",
    "plt.title('Courbe de précision-rappel')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_val,lg.predict(X_val))*100)\n",
    "    \n",
    "acc = accuracy_score(y_val,lg.predict(X_val))*100\n",
    "acc_score.append(acc)\n",
    "print(\"Score : \",acc)    \n",
    "y_pred_1.append(lg.predict_proba(X_main_test))\n",
    "    \n",
    "\n",
    "\n",
    "# preds_1[i+1]=lg.predict_proba(X_main_test)\n",
    "# y_pred_1.append(lg.predict_proba(X_main_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final_1 = np.mean(np.array(y_pred_1),axis=0)\n",
    "    \n",
    "print('mean accuracy score: {}'.format((sum(acc_score)/10)))\n",
    "\n",
    "preds_1=np.argmax(y_pred_final_1,axis=1)\n",
    "\n",
    "print(preds_1.shape)\n",
    "submission_df['Stay']=le.inverse_transform(preds_1.astype(int))\n",
    "# submission_df[0] = y_pred_final_1[:,0]\n",
    "# submission_df[1] =y_pred_final_1[:,1]\n",
    "\n",
    "# Download Submission File :\n",
    "display(\"submission_df\",submission_df)\n",
    "sub_file_name_1 = \"BEST_11_CV=42.96_LB=WAIT_LGBM-1.csv\"\n",
    "\n",
    "\n",
    "submission_df.to_csv(sub_file_name_1,index=False)\n",
    "submission_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
